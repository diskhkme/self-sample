 
<!DOCTYPE html>
<head>
    <meta charset="utf-8"/>
    <title>Self-Sample</title>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
          integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <meta content="width=device-width, initial-scale=1" name="viewport"/>
    <link href="min.css" rel="stylesheet" type="text/css"/>
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({google: {families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]}});</script>
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"
            type="text/javascript"></script>
    <![endif]-->
    <script type="text/javascript">!function (o, c) {
        var n = c.documentElement, t = " w-mod-";
        n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
    }(window, document);</script>
    <link href="images/thumbnail.png"
          rel="shortcut icon" type="image/x-icon"/>
    <style>
        .wf-loading * {
            opacity: 0;
        }
    </style>

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">

</head>
<body>


<!--<div class="row">-->
<!--    <div class="cell"><img src="images/sig2020.svg" width="200"></div>-->
<!--</div>-->

<div class="section hero p2m">
    <div class="container-2 p2m_header_v2 w-container"><h1 class="title">Self-Sampling</h1>
        <h1 class="subheader"> for neural point cloud consolidation</h1>
        <div class="p2m_authors_list_single w-row">
            <div class="w-col w-col-3 w-col-small-2 w-col-tiny-6">
                <a class="authors" href="https://galmetzer.github.io/" target="_blank">Gal Metzer</a></div>
            <div class="w-col w-col-3 w-col-small-4 w-col-tiny-6">
                <a class="authors" href="https://www.cs.tau.ac.il/~hanocka/" target="_blank">Rana Hanocka</a></div>
            <div class="w-col w-col-3 w-col-small-2 w-col-tiny-6">
                <a class="authors" href="http://web.eng.tau.ac.il/~raja/" target="_blank">Raja Giryes</a></div>
            <div class="w-col w-col-3 w-col-small-4 w-col-tiny-6">
                <a class="authors" href="https://www.cs.tau.ac.il/~dcor/" target="_blank">Daniel Cohen-Or</a>
            </div>
        </div>
        <div class="div-block-10">
            <div class="equal_v2">Tel Aviv University</div>
        </div>

        <div style="clear: both;display: table;">
            <br>
            <span class="center"><img style="width: 70%" src="images/lamp-teaser.jpg"></span>
        </div>

        <!--start links -->
        <div class="p2m_authors_list_single w-row">
            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <a class="authors" href="" target="_blank">
                    <a href="https://arxiv.org/abs/2008.06471" target="_blank"><i
                            class="far fa-4x fa-file text-primary mb-3 "></i></a>
                </a></div>

            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <a class="authors" href="" target="_blank">

                </a></div>

            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <a class="authors" href="" target="_blank">
                    <a href="https://github.com/galmetzer/self-sample" target="_blank"><i
                            class="fab fa-4x fa-github text-primary mb-3 "></i></a>
                </a></div>


        </div>


        <div class="div-block-4 w-row">
            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <div class="text-block-2"><strong style="color:#18446c" class="icon-bold-text">Paper</strong></div>
            </div>

            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <div class="text-block-2"><strong style="color:#18446c" class="icon-bold-text"></strong></div>
            </div>

            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">
                <div class="text-block-2">
                    <strong style="color:#18446c" class="icon-bold-text">Code</strong>
                </div>
            </div>
<!--            <div class="w-col w-col-4 w-col-small-3 w-col-tiny-4">-->
<!--                <div class="text-block-2"><strong style="color:#18446c" class="icon-bold-text">Slides</strong></div>-->
<!--            </div>-->
        </div>
    </div>

    <!--  end links  -->
</div>
</div>

<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Abstract</h2>
        <p class="paragraph-3 the_text">
            We introduce a novel technique for neural point cloud consolidation which learns from only the input point cloud.
            Unlike other point upsampling methods which analyze shapes via local patches, in this work, we learn from global subsets.
            We repeatedly self-sample the input point cloud with global subsets that are used to train a deep neural network.
            Specifically, we define source and target subsets according to the desired consolidation criteria (e.g., generating sharp points or points in sparse regions).
            The network learns a mapping from source to target subsets, and implicitly learns to consolidate the point cloud.
            During inference, the network is fed with random subsets of points from the input, which it displaces to synthesize a consolidated point set.
            We leverage the inductive bias of neural networks to eliminate noise and outliers, a notoriously difficult problem in point cloud consolidation.
            The shared weights of the network are optimized over the entire shape,
            learning non-local statistics and exploiting the recurrence of local-scale geometries.
            Specifically, the network encodes the distribution of the underlying shape surface within a fixed set of local kernels,
            which results in the best explanation of the underlying shape surface.
            We demonstrate the ability to consolidate point sets from a variety of shapes, while eliminating outliers and noise.
        </p>
    </div>
</div>


<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Self-Sampling Overview</h2>
        <p class="paragraph-3 the_text" >
            We train a network to generate a consolidated set of points using the self-supervision present within a single input point cloud.
             We define source (blue) and target (red) subsets according to the desired consolidation criterion
            (e.g., generating sharp points or points in sparse regions).
        </p>
        <div><span class="center" id="lableing" ><img src="images/curve.png"></span></div>
         <p class="paragraph-3 the_text">
             We repeatedly self-sample the input point cloud with global subsets which are used to train a deep neural network.
             The subsets are balanced according to the consolidation criterion, for example sharpness in the example below.
        </p>
        <div><span class="center"><img style="width: 50%" src="images/sampling_figure.png"></span></div>

        <p class="paragraph-3 the_text">
            The network is trained on disjoint pairs of source and target subsets,
            and implicitly learns to consolidate the point cloud by generating offsets which are added to the input source points such that they resemble a target subset (i.e., predicted target subset).

        </p>
        <div><span class="center"><img src="images/overview.jpg"></span></div>


    <p class="paragraph-3 the_text">
        During inference, the network is fed with random subsets of points from the input,
        which it displaces to synthesize a consolidated point set.
        This process is repeated to obtain an arbitrarily large set of consolidated points with an emphasis
        on the consolidation criterion (\emph{e.g.,} sharp feature points or points in sparsely sampled regions).
        </p>
        <div><span class="center"><img src="images/inference.png"></span></div>

    <p class="paragraph-3 the_text">
    The network is able to generalize and express novelty in the generation of new points at inference time.
     The diversity in novel sharp feature generation can be seen in the figure below.
        Given an input point(red) and random subsets from the input point cloud (entire point cloud in blue),
        our network generates different displacements which are added to the input point to generate a variety of different output points (yellow).
        Novel points on the surface are conditioned on the selected input subset, and thus can be different at each forward pass.
    </p>
    <div><span class="center"><img style="width: 70%" src="images/patches.png"></span></div>


    </div>

</div>

<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Results</h2>

        <div><span class="center"><img style="width: 70%" src="images/results/alien2.jpg"></span></div>
        <p class="paragraph-3 the_text">
            Edge consolidation result of an alien shape with sharp edges.
        </p>

        <div><span class="center"><img style="width: 70%" src="images/results/alien-size.jpg"></span></div>

        <p class="paragraph-3 the_text">
            As the number of forward passes increases at inference, the higher the verity of the output is.
        </p>
        <div> <span class="center"><img style="width: 70%" src="images/anky-teaser.png"></span></div>
        <div><span class="center"><img style="width: 50%" src="images/results/bear_mesh.png"></span></div>

        <p class="paragraph-3 the_text">
            Increasing the density of points in sparse regions leads to a better post process mesh reconstruction.
        </p>

        <div><span class="center"><img style="width: 70%" src="images/results/scanned_cube.jpg"></span></div>
        <p class="paragraph-3 the_text">
            Left is the real scanned input, middle is EC-Net, and right is ours.
            A sparsely sampled edges is recovered by our method.
        </p>

        <div><span class="center"><img style="width: 50%" src="images/results/cube_denoise.png"></span></div>
        <p class="paragraph-3 the_text">
            When running our method with random subsampling
            we achieve denoising, as the network is not able to overfit the noise.
        </p>

    </div>
</div>


<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Citation</h2>
        <pre class="citation">@article{metzer2020self,
          title={Self-Sampling for Neural Point Cloud Consolidation},
          author={Metzer, Gal and Hanocka, Rana and Giryes, Raja and Cohen-Or, Daniel},
          journal={arXiv preprint arXiv:2008.06471},
          year={2020}
        }
        </pre>
    </div>
</div>

<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Acknowledgements</h2>
        <p class="paragraph-3 the_text">
            We thank <a class= "link" href="http://shihaowu.net/" target="_blank">Shihao Wu</a> for his helpful suggestions,
            and <a class= "link" href="https://nini-lxz.github.io/" target="_blank">Xianzhi Li</a> for providing data for comparisons.
            </br>
            We also thank <a class= "link" href="https://www.linkedin.com/in/guy-yoffe-b0a12119a" target="_blank">Guy Yoffe</a> for providing real point cloud scans.
            </br>
            This work is supported by the European research council (ERC-StG 757497 PI Giryes),
            and the Israel Science Foundation (grants no. 2366/16 and 2492/20).

        </p>
    </div>
</div>

</body></html>